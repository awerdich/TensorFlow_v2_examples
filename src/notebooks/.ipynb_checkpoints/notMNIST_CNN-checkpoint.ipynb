{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN for classifying notMNIST images ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.11.0\n",
      "Keras version 2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "# Dataset processing\n",
    "from notMNIST_dataset.notMNIST_processing import plot_imrow, DatasetProvider\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras version', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model class ###\n",
    "We will user Keras layers to build the network. Keras layers can be called on TendsorFlow tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL CLASS\n",
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, data_root, input_dim, n_classes, scope):\n",
    "        \n",
    "        self.data_root = data_root # Location of .tfrecords files and LOG folders\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.scope = scope\n",
    "        self.graph = None\n",
    "\n",
    "    def examine_model_structure(self):\n",
    "        \n",
    "        # Build a graph to get the model information\n",
    "        with tf.Graph().as_default():\n",
    "\n",
    "            inputs = tf.placeholder(tf.float32, shape=(None, *input_dim))\n",
    "\n",
    "            # Build model, here just for getting the model parameters\n",
    "            net = self.graph(inputs)\n",
    "\n",
    "            # Get the trainable variables\n",
    "            tvars = tf.trainable_variables()\n",
    "            \n",
    "            # Start a session\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                tvars_val = sess.run(tvars)\n",
    "                names = [var.name for var in tvars]\n",
    "                shapes = [var.shape for var in tvars_val]\n",
    "                num_vars = [np.product(tup) for tup in shapes]\n",
    "                model_dict = {'tensor_name': names,\n",
    "                              'tensor_shape': shapes,\n",
    "                              'num_vars': num_vars}\n",
    "                \n",
    "                model_df = pd.DataFrame(model_dict)\n",
    "                print()\n",
    "                print('Tensors and trainable parameters:\\n')\n",
    "                print(model_df, '\\n')\n",
    "                print('Total number of trainable parameters:', np.sum(model_df.num_vars))\n",
    "                writer = tf.summary.FileWriter(logdir = os.path.join(data_root, 'log_graph'), graph = sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNmodel(Model):\n",
    "    \n",
    "    '''Convolutional neural network for notMNIST classification\n",
    "    data_root: folder with .tfrecords files\n",
    "    input_dim: (28, 28, 1)\n",
    "    output_dim: (10,)'''\n",
    "\n",
    "    def __init__(self, data_root, input_dim, n_classes, scope):\n",
    "        Model.__init__(self, data_root, input_dim, n_classes, scope)\n",
    "        self.graph = self.CNN_notMNIST_classifier\n",
    "\n",
    "    def CNN_notMNIST_classifier(self, inputs, is_training=True, dropout=0.5):\n",
    "        \n",
    "        '''CNN_classifier for original notMNIST dataset.'''\n",
    "        \n",
    "        with tf.name_scope(self.scope, 'CNN_notMNIST_classifier', [inputs]) as vs:\n",
    "            \n",
    "            # Keras layers\n",
    "            net = layers.Conv2D(32, [3, 3], activation = tf.nn.relu)(inputs)\n",
    "            net = layers.Conv2D(63, [3, 3], activation = tf.nn.relu)(net)\n",
    "            net = layers.MaxPooling2D([2, 2])(net)\n",
    "            net = layers.Dropout(dropout)(net)\n",
    "            \n",
    "            # We will use a convolutional layer instead of a fully connected layer\n",
    "            net = layers.Conv2D(128, [12, 12], activation = tf.nn.relu)(net)\n",
    "            net = layers.Dropout(dropout)(net)\n",
    "            net = layers.Conv2D(self.n_classes, [1, 1], activation = None)(net)\n",
    "            net = tf.squeeze(net)\n",
    "            \n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensors and trainable parameters:\n",
      "\n",
      "              tensor_name       tensor_shape  num_vars\n",
      "0    CNN1/conv2d/kernel:0      (3, 3, 1, 32)       288\n",
      "1      CNN1/conv2d/bias:0              (32,)        32\n",
      "2  CNN1/conv2d_1/kernel:0     (3, 3, 32, 63)     18144\n",
      "3    CNN1/conv2d_1/bias:0              (63,)        63\n",
      "4  CNN1/conv2d_2/kernel:0  (12, 12, 63, 128)   1161216\n",
      "5    CNN1/conv2d_2/bias:0             (128,)       128\n",
      "6  CNN1/conv2d_3/kernel:0    (1, 1, 128, 10)      1280\n",
      "7    CNN1/conv2d_3/bias:0              (10,)        10 \n",
      "\n",
      "Total number of trainable parameters: 1181161\n"
     ]
    }
   ],
   "source": [
    "data_root = os.path.normpath('/home/andy/vbshare/notMNISTdata')\n",
    "input_dim = (28, 28, 1)\n",
    "n_classes = 10\n",
    "notMNISTmodel = CNNmodel(data_root, input_dim, n_classes, 'CNN1')\n",
    "notMNISTmodel.examine_model_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./CNN1_graph.png' style='transform:rotate(0deg); width:600px; height:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation ##\n",
    "We will use the following code to build a ModelTrainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders\n",
    "data_root = os.path.normpath('/home/andy/vbshare/notMNISTdata')\n",
    "\n",
    "# Create the checkpoint folder if it does not exist\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "# Data sets\n",
    "train_filename = 'train_dataset.tfrecords'\n",
    "valid_filename = 'valid_dataset.tfrecords'\n",
    "\n",
    "# Training/testing parameters\n",
    "train_batch_size = 256\n",
    "test_batch_size = 1024\n",
    "input_dim = (28, 28, 1)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for the ModelTrainer class\n",
    "def build_dataset(file, batch_size):\n",
    "    \n",
    "    dataset = DatasetProvider([os.path.join(data_root, file)])\n",
    "    dataset_records = dataset.count_records()[0]\n",
    "    dataset_iter_per_epoch = int(np.ceil(dataset_records/batch_size))\n",
    "    print('Records in dataset:', dataset_records)\n",
    "    print('Iterations per epoch:', dataset_iter_per_epoch)\n",
    "    \n",
    "    return dataset.make_batch(batch_size, shuffle = True)\n",
    "\n",
    "def accuracy(predicted_labels, true_labels):\n",
    "        correct_predictions = tf.equal(predicted_labels, true_labels)\n",
    "        acc = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "        return acc\n",
    "\n",
    "def prerec(predicted_labels, true_labels):\n",
    "    '''real precision and recall values for predictions'''\n",
    "    cm = tf.confusion_matrix(true_labels, predicted_labels)\n",
    "    # precision: diagonal elements divided by sum of each column\n",
    "    pr = tf.divide(tf.diag_part(cm), tf.reduce_sum(cm, axis = 0))\n",
    "    # recall: diagonal elements divided by sum of each row\n",
    "    re = tf.divide(tf.diag_part(cm), tf.reduce_sum(cm, axis = 1))\n",
    "    return pr, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the graph ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in dataset: 395861\n",
      "Iterations per epoch: 1547\n",
      "Records in dataset: 17797\n",
      "Iterations per epoch: 18\n"
     ]
    }
   ],
   "source": [
    "# We use a named graph here to access it through a session later\n",
    "model_graph = tf.Graph()\n",
    "with model_graph.as_default():\n",
    "    \n",
    "    # Global step variable\n",
    "    global_step_tensor = tf.Variable(0, trainable = False, name = 'global_step')\n",
    "    \n",
    "    # Placeholders\n",
    "    with tf.name_scope('Placeholders'):\n",
    "        iterator_handle = tf.placeholder(tf.string, shape = [], name = 'iterator_handle')\n",
    "        \n",
    "        \n",
    "    # Datasets\n",
    "    with tf.name_scope('Datasets'):\n",
    "        train_dataset = build_dataset(train_filename, train_batch_size)\n",
    "        val_dataset = build_dataset(valid_filename, test_batch_size)\n",
    "    \n",
    "    # Generalized iterator\n",
    "    with tf.name_scope('Iterators'):\n",
    "        \n",
    "        # Iterators\n",
    "        gen_iterator = tf.data.Iterator.from_string_handle(iterator_handle,\n",
    "                                                           output_types = train_dataset.output_types,\n",
    "                                                           output_shapes = train_dataset.output_shapes)\n",
    "        \n",
    "        \n",
    "        train_iterator = train_dataset.make_initializable_iterator()\n",
    "        val_iterator = val_dataset.make_initializable_iterator()\n",
    "        \n",
    "        # Initialize the iterators\n",
    "        train_init = train_iterator.initializer\n",
    "        val_init = val_iterator.initializer\n",
    "        \n",
    "        # Next element op\n",
    "        image_batch, label_batch = gen_iterator.get_next()\n",
    "        # We need provide the shape of a batch to the graph (because the dataset does not provide it)\n",
    "        image_batch.set_shape((None, *input_dim))\n",
    "        # convert the labels to one_hot encoded vectors\n",
    "        label_one_hot = tf.one_hot(label_batch, depth = n_classes)\n",
    "        \n",
    "    # Build the model\n",
    "    model = CNNmodel(data_root, input_dim, n_classes, 'CNN')\n",
    "    logits = model.graph(image_batch)\n",
    "    is_training = K.learning_phase()\n",
    "    \n",
    "    # Cross entropy and loss\n",
    "    with tf.name_scope('Loss'):\n",
    "        xent = tf.nn.softmax_cross_entropy_with_logits_v2(labels = label_one_hot,\n",
    "                                                          logits = logits,\n",
    "                                                          name = 'xent')\n",
    "        loss = tf.reduce_mean(xent)\n",
    "        \n",
    "    # Optimization. We also save the global_step so that we can continue training\n",
    "    with tf.name_scope('Optimization'):\n",
    "        train_step = tf.train.AdadeltaOptimizer(0.001).minimize(loss, global_step = global_step_tensor)\n",
    "        \n",
    "    # Accuracy\n",
    "    preds = tf.argmax(tf.nn.softmax(logits), axis = 1)\n",
    "    acc = accuracy(preds, label_batch)\n",
    "    \n",
    "    # Checkpoints\n",
    "    saver = tf.train.Saver() # saving and retrieving data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy and early stopping ###\n",
    "The classification accuracy for the validation set will be calculated for every 100 iterations. The optimization will be stopped if the validation accuracy has not improved in 1000 iterations. We need a few variables to keep track of this. Instead of accuracy, we can also apply the same stopping criteria to the loss. This may be more important because the accuracy may not improve while the loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best accuracy seen so far\n",
    "best_validation_accuracy = 0.0\n",
    "\n",
    "# Iteration number for last improvement to validation accuracy\n",
    "last_improvement = 0\n",
    "\n",
    "# Stop optimization if no improvement found in this many iterations\n",
    "require_improvement = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training session ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensors and trainable parameters:\n",
      "\n",
      "             tensor_name       tensor_shape  num_vars\n",
      "0    CNN/conv2d/kernel:0      (3, 3, 1, 32)       288\n",
      "1      CNN/conv2d/bias:0              (32,)        32\n",
      "2  CNN/conv2d_1/kernel:0     (3, 3, 32, 63)     18144\n",
      "3    CNN/conv2d_1/bias:0              (63,)        63\n",
      "4  CNN/conv2d_2/kernel:0  (12, 12, 63, 128)   1161216\n",
      "5    CNN/conv2d_2/bias:0             (128,)       128\n",
      "6  CNN/conv2d_3/kernel:0    (1, 1, 128, 10)      1280\n",
      "7    CNN/conv2d_3/bias:0              (10,)        10 \n",
      "\n",
      "Total number of trainable parameters: 1181161\n",
      "Iter:      1, train_acc:   8.6%, val_acc:  11.3%, train_loss:   2.32 *\n",
      "Iter:    101, train_acc:  12.9%, val_acc:  11.1%, train_loss:   2.29 \n",
      "Iter:    201, train_acc:  14.1%, val_acc:  12.4%, train_loss:   2.28 *\n",
      "Iter:    301, train_acc:  18.8%, val_acc:  17.3%, train_loss:   2.27 *\n",
      "Iter:    400, train_acc:  21.9%, val_acc:  23.7%, train_loss:   2.26 *\n",
      "Time usage:  0:00:16\n"
     ]
    }
   ],
   "source": [
    "num_iterations = int(400)\n",
    "# Checkpoint folder: need to exist\n",
    "checkpoint_dir = os.path.join(data_root, 'checkpoints')\n",
    "\n",
    "# Model name\n",
    "save_path = os.path.join(checkpoint_dir, 'model')\n",
    "\n",
    "# Run training for the graph\n",
    "with model_graph.as_default():\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Save model parameters\n",
    "        model.examine_model_structure()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run([train_init, val_init]) \n",
    "        train_handle, val_handle = sess.run([train_iterator.string_handle(),\n",
    "                                                          val_iterator.string_handle()])\n",
    "        \n",
    "        # session dicts\n",
    "        train_dict = {iterator_handle: train_handle, K.learning_phase(): 1}\n",
    "        train_dict_eval = {iterator_handle: train_handle, K.learning_phase(): 0}\n",
    "        val_dict = {iterator_handle: val_handle, K.learning_phase(): 0}\n",
    "        \n",
    "        # Keeping track of time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for step in range(0, num_iterations):\n",
    "            \n",
    "            # Run optimization step\n",
    "            sess.run(train_step, feed_dict = train_dict)\n",
    "            \n",
    "            # Print the status every 100 iterations and after the last iteration\n",
    "            if (step % 100 == 0) or (step == (num_iterations - 1)):\n",
    "                \n",
    "                # Loss and accuracy on the training batch\n",
    "                train_loss, train_acc = sess.run([loss, acc], feed_dict = train_dict_eval)\n",
    "                \n",
    "                # Loss and accuracy on the validation batch\n",
    "                val_loss, val_acc = sess.run([loss, acc], feed_dict = val_dict)\n",
    "                \n",
    "                # If validation accuracy is an improvement over best-known\n",
    "                if val_acc > best_validation_accuracy:\n",
    "                    \n",
    "                    # Update the best known accuracy\n",
    "                    best_validation_accuracy = val_acc\n",
    "                    \n",
    "                    # Set the iteration for the last improvement to current\n",
    "                    last_improvement = step\n",
    "                    \n",
    "                    # This is an improvement, so we save the weights\n",
    "                    saver.save(sess, save_path = save_path, global_step = step)\n",
    "                    \n",
    "                    # A string to be printed below, shows improvement found\n",
    "                    improved_str = '*'\n",
    "                \n",
    "                else:\n",
    "                    # An empty string printed below shows that no improvement was made\n",
    "                    improved_str = ''\n",
    "                \n",
    "                # Status-message for printing\n",
    "                msg = 'Iter: {0:>6}, train_acc: {1:>6.1%}, val_acc: {2:>6.1%}, train_loss: {3:>6.3} {4}'\n",
    "                \n",
    "                # Print it\n",
    "                print(msg.format(step + 1, train_acc, val_acc, train_loss, improved_str))\n",
    "                \n",
    "            # If no improvement was found in the required number of iterations\n",
    "            if (step - last_improvement) > require_improvement:\n",
    "                print('No improvement found. Stopping optimization.')\n",
    "                \n",
    "                # Break out from the loop\n",
    "                break\n",
    "        \n",
    "        # Ending time\n",
    "        end_time = time.time()\n",
    "        time_dif = end_time - start_time\n",
    "        \n",
    "        # Print the time usage\n",
    "        print('Time usage: ', timedelta(seconds = int(round(time_dif))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in dataset: 395861\n",
      "Iterations per epoch: 3093\n",
      "INFO:tensorflow:Restoring parameters from /home/andy/vbshare/notMNISTdata/checkpoints/model-399\n",
      "Accuracy 0.421875\n",
      "Current training step: 800\n"
     ]
    }
   ],
   "source": [
    "# Restore model and continue training\n",
    "tf.reset_default_graph()\n",
    "train_filename = 'train_dataset.tfrecords'\n",
    "data_root = os.path.normpath('/home/andy/vbshare/notMNISTdata')\n",
    "checkpoint_dir = os.path.join(data_root, 'checkpoints')\n",
    "save_path = os.path.join(checkpoint_dir, 'best_validation')\n",
    "input_dim = (28, 28, 1)\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "n_iterations = 800\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # Global step variable: needed to keep track of global_step\n",
    "    current_step = tf.Variable(0, trainable = False, name = 'global_step')\n",
    "    \n",
    "    dataset = build_dataset(train_filename, batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "    iterator_init = iterator.initializer\n",
    "    \n",
    "    image, label = iterator.get_next()\n",
    "    image.set_shape((batch_size, *input_dim))\n",
    "    one_hot_label = tf.one_hot(label, depth = n_classes)\n",
    "    \n",
    "    # set up the model\n",
    "    model = CNNmodel(data_root, input_dim, n_classes, scope = 'CNN')\n",
    "    logits = model.graph(image)\n",
    "    is_training = K.learning_phase()\n",
    "    \n",
    "    # Cross entropy and loss\n",
    "    with tf.name_scope('Loss'):\n",
    "        xent = tf.nn.softmax_cross_entropy_with_logits_v2(labels = one_hot_label,\n",
    "                                                          logits = logits,\n",
    "                                                          name = 'xent')\n",
    "        loss = tf.reduce_mean(xent)\n",
    "        \n",
    "    # Optimization. We also save the global_step so that we can continue training\n",
    "    with tf.name_scope('Optimization'):\n",
    "        train_step = tf.train.AdadeltaOptimizer(0.001).minimize(loss, global_step = current_step)\n",
    "        \n",
    "    # Accuracy\n",
    "    preds = tf.argmax(tf.nn.softmax(logits), axis = 1)\n",
    "    acc = accuracy(preds, label)\n",
    "    \n",
    "    # Checkpoints\n",
    "    saver = tf.train.Saver() # saving and retrieving data\n",
    "    \n",
    "    # Restore the weights and run a prediction\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        sess.run(iterator_init)\n",
    "        #sess.run(tf.variables_initializer([global_step_tensor]))\n",
    "    \n",
    "        # Restore weights\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "        \n",
    "        # Continue training\n",
    "        start_step = sess.run(current_step)\n",
    "        for step in range(start_step, n_iterations):\n",
    "            \n",
    "            sess.run(train_step)\n",
    "        \n",
    "        print('Accuracy', sess.run(acc))\n",
    "        print('Current training step:', sess.run(current_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run test set ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and restore models ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in dataset: 395861\n",
      "Iterations per epoch: 3093\n",
      "Accuracy: 0.296875\n",
      "step_tensor: 259\n",
      "INFO:tensorflow:Restoring parameters from /home/andy/vbshare/notMNISTdata/checkpoints/best_validation\n",
      "Accuracy: 0.328125\n",
      "step_tensor: 259\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_filename = 'train_dataset.tfrecords'\n",
    "data_root = os.path.normpath('/home/andy/vbshare/notMNISTdata')\n",
    "checkpoint_dir = os.path.join(data_root, 'checkpoints')\n",
    "save_path = os.path.join(checkpoint_dir, 'best_validation')\n",
    "input_dim = (28, 28, 1)\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    with tf.name_scope('non_trainable_vars'):\n",
    "        step_tensor = tf.Variable(0, trainable = False, name = 'global_step')\n",
    "    \n",
    "    dataset = build_dataset(train_filename, batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "    iterator_init = iterator.initializer\n",
    "    \n",
    "    image, label = iterator.get_next()\n",
    "    image.set_shape((batch_size, *input_dim))\n",
    "    one_hot_label = tf.one_hot(label, depth = n_classes)\n",
    "    \n",
    "    # set up the model\n",
    "    model = CNNmodel(data_root, input_dim, n_classes, scope = 'CNN_1')\n",
    "    logits = model.graph(image)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = one_hot_label)\n",
    "    train_step = tf.train.AdadeltaOptimizer(0.001).minimize(loss, global_step = step_tensor)\n",
    "    \n",
    "    # accuracy\n",
    "    acc = accuracy(tf.argmax(logits, 1), label)\n",
    "    \n",
    "    # saver object\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run([tf.global_variables_initializer(), iterator_init])\n",
    "        loss_val = sess.run(loss)\n",
    "        \n",
    "        for step in range(259):\n",
    "            # Run a few training steps\n",
    "            sess.run(train_step)\n",
    "        \n",
    "        #Init iterator again\n",
    "        sess.run(iterator_init)\n",
    "        \n",
    "        # Get the accuracy\n",
    "        print('Accuracy:', sess.run(acc))\n",
    "        print('step_tensor:', sess.run(step_tensor))\n",
    "        \n",
    "        # Save the model\n",
    "        saver.save(sess = sess, save_path = save_path)\n",
    "        \n",
    "    # Restore the model\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(iterator_init)\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Restore weights\n",
    "        saver.restore(sess = sess, save_path = save_path)\n",
    "            \n",
    "        print('Accuracy:', sess.run(acc))\n",
    "        print('step_tensor:', sess.run(step_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in dataset: 14802\n",
      "Iterations per epoch: 116\n",
      "INFO:tensorflow:Restoring parameters from /home/andy/vbshare/notMNISTdata/checkpoints/best_validation\n",
      "Accuracy: 0.359375\n",
      "step_tensor: 259\n",
      "['non_trainable_vars/global_step/initial_value', 'non_trainable_vars/global_step', 'non_trainable_vars/global_step/Assign', 'non_trainable_vars/global_step/read', 'Const']\n"
     ]
    }
   ],
   "source": [
    "# Can we re-create the model and restore the weights?\n",
    "tf.reset_default_graph()\n",
    "test_filename = 'test_dataset.tfrecords'\n",
    "data_root = os.path.normpath('/home/andy/vbshare/notMNISTdata')\n",
    "checkpoint_dir = os.path.join(data_root, 'checkpoints')\n",
    "save_path = os.path.join(checkpoint_dir, 'best_validation')\n",
    "input_dim = (28, 28, 1)\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    #with tf.name_scope('non_trainable_vars'):\n",
    "    step_tensor_new = tf.Variable(0, trainable = False, name = 'non_trainable_vars/global_step')\n",
    "    \n",
    "    dataset = build_dataset(test_filename, batch_size)\n",
    "    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "    iterator_init = iterator.initializer\n",
    "    \n",
    "    image, label = iterator.get_next()\n",
    "    image.set_shape((batch_size, *input_dim))\n",
    "    one_hot_label = tf.one_hot(label, depth = n_classes)\n",
    "    \n",
    "    # set up the model\n",
    "    model1 = CNNmodel(data_root, input_dim, n_classes, scope = 'CNN_1')\n",
    "    logits = model1.graph(image)\n",
    "    \n",
    "    # accuracy\n",
    "    acc1 = accuracy(tf.argmax(logits, 1), label)\n",
    "    \n",
    "    # saver object\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator_init)\n",
    "        \n",
    "        # Restore weights\n",
    "        saver.restore(sess = sess, save_path = save_path)\n",
    "            \n",
    "        print('Accuracy:', sess.run(acc1))\n",
    "        print('step_tensor:', sess.run(step_tensor_new))\n",
    "        \n",
    "        # Print all tensors\n",
    "        names = [n.name for n in tf.get_default_graph().as_graph_def().node] \n",
    "        print(names[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: (256, 28, 28, 1)\n",
      "Image size: (28, 28)\n",
      "Mean: 9.73137e-09\n",
      "Standard deviation: 1.0\n",
      "Min value: -0.78386855\n",
      "Max value: 1.5189779\n"
     ]
    }
   ],
   "source": [
    "# Label lookup\n",
    "letters = [chr(65+i) for i in range(n_classes)]\n",
    "label_dict = dict(zip(range(n_classes), letters))\n",
    "\n",
    "image_list = [image_val[i, :, :, 0] for i in range(6)]\n",
    "label_list = [label_dict[label] for label in [label_val[i] for i in range(6)]]\n",
    "\n",
    "fig = plot_imrow(image_list, label_list)\n",
    "\n",
    "# Some image statistics on sample image\n",
    "im = image_list[0]\n",
    "print('Batch size:', image_val.shape)\n",
    "print('Image size:', im.shape)\n",
    "print('Mean:', np.mean(im))\n",
    "print('Standard deviation:', np.std(im))\n",
    "print('Min value:', np.min(im))\n",
    "print('Max value:', np.max(im))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
